{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sigmoid.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO8w7N5mMPnLAYbnlsrBgQ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kipsangchepesa/core-module-1/blob/main/sigmoid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fKgHcU8-Log"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR3FWJiJ-QtZ"
      },
      "source": [
        "def sigmoid(z):\n",
        "  return 1.0 / (1 + np.exp(-z))\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbVyaAO0-VDk",
        "outputId": "b1ca9b18-f1d3-40bf-d978-ff2daedf1959"
      },
      "source": [
        "sigmoid(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999546021312976"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CYFQxwY-QqZ",
        "outputId": "02fb8ab2-7f30-4b1c-d72a-e8c4923d9137"
      },
      "source": [
        "sigmoid(4)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9820137900379085"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwPtw9W0BsL6"
      },
      "source": [
        "# interpretation pâ‰¥0.5,class=1, true  and p<0.5,class=0, false\n",
        "# For example, if our threshold was .5 and our prediction function returned .7, \n",
        "# we would classify this observation as positive. \n",
        "# If our prediction was .2 we would classify the observation as negative. \n",
        "# For logistic regression with multiple classes we could select the class with the highest predicted probability.\n",
        "#As the probability gets closer to 1, our model is more confident that the observation is in class 1."
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OPVYKKhDnre"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aszzuOF5DmYa"
      },
      "source": [
        "def predict(features, weights):\n",
        "  '''\n",
        "  Returns 1D array of probabilities\n",
        "  that the class label == 1\n",
        "  '''\n",
        "  z = np.dot(features, weights)\n",
        "  return sigmoid(z)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5QoWmk6Ehda"
      },
      "source": [
        "def decision_boundary(prob):\n",
        "  return 1 if prob >= .5 else 0"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9xsUp-9E6jl"
      },
      "source": [
        "def plot_decision_boundary(trues, falses):\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111)\n",
        "\n",
        "    no_of_preds = len(trues) + len(falses)\n",
        "\n",
        "    ax.scatter([i for i in range(len(trues))], trues, s=25, c='b', marker=\"o\", label='Trues')\n",
        "    ax.scatter([i for i in range(len(falses))], falses, s=25, c='r', marker=\"s\", label='Falses')\n",
        "\n",
        "    plt.legend(loc='upper right');\n",
        "    ax.set_title(\"Decision Boundary\")\n",
        "    ax.set_xlabel('N/2')\n",
        "    ax.set_ylabel('Predicted Probability')\n",
        "    plt.axhline(.5, color='black')\n",
        "    plt.show()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sB3zyuqjGvDK"
      },
      "source": [
        "# import sklearn\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# #from sklearn.cross_validation import train_test_split\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Normalize grades to values between 0 and 1 for more efficient computation\n",
        "# normalized_range = sklearn.preprocessing.MinMaxScaler(feature_range=(-1,1))\n",
        "\n",
        "# # Extract Features + Labels\n",
        "# labels.shape =  (100,) #scikit expects this\n",
        "# features = normalized_range.fit_transform(features)\n",
        "\n",
        "# # Create Test/Train\n",
        "# features_train,features_test,labels_train,labels_test = train_test_split(features,labels,test_size=0.4)\n",
        "\n",
        "# # Scikit Logistic Regression\n",
        "# scikit_log_reg = LogisticRegression()\n",
        "# scikit_log_reg.fit(features_train,labels_train)\n",
        "\n",
        "# #Score is Mean Accuracy\n",
        "# scikit_score = clf.score(features_test,labels_test)\n",
        "# print ('Scikit score: ')#, scikit_score\n",
        "\n",
        "# #Our Mean Accuracy\n",
        "# observations, features, labels, weights = run()\n",
        "# probabilities = predict(features, weights).flatten()\n",
        "# classifications = classifier(probabilities)\n",
        "# our_acc = accuracy(classifications,labels.flatten())\n",
        "# print ('Our score: ')\n",
        "# #,our_acc"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}